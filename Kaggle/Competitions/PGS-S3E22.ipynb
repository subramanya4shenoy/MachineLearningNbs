{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# â›³ï¸ 1. Look at the Big picture \nğŸŸ¢ Read, Understand the Problem\n\n### ğŸ”¸ Frame the problem\n* ğŸ¥‡ Note what we want to acheive.\n* ğŸ¥‡ Form a hypothesis and decide the end goal and identify the format to acheive.\n* ğŸ¥‡ Decide on :\n* * ğŸ¥ˆ Learning? : Supervised / Unsupervised / Reinfored\n* * ğŸ¥ˆ Problem type? : Classification/Regression\n* * ğŸ¥ˆ Univariate/BiVariate ?\n* * ğŸ¥ˆ Single target or Multi target ?\n\n### ğŸ”¸ Select Performance measure\n* ğŸ¥‡  RMSE\n* ğŸ¥‡  MAE (best fit if there are many outliers)\n\n### ğŸ”¸ Check for Assumptions\n* ğŸ¥‡ Check for general information about the topic. Get the assumptions and features which needs more conciderations. etc..","metadata":{}},{"cell_type":"markdown","source":"\nã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°\n# Observation\n\n* ğŸ¥‡ want to get a column which says horse survived or not (lived / died)\n* \nã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°ã€°\n\n","metadata":{}},{"cell_type":"markdown","source":"# â›³ï¸ 2. Get the Data\nğŸŸ¢ Make sure you collect the data from trusted sources and legal sources.\n\n### ğŸ”¸ Take a quick look\n* ğŸ¥‡ Read the Data into a panda dataframe \n* ğŸ¥‡ **.head()** check for the columns and values represented\n* ğŸ¥‡ **.info()** check for non-null and datatypes presented\n* ğŸ¥‡ **.value_counts()** check for each category columns occurances of value\n* ğŸ¥‡ **.describe()** check for mean, min, max, std values of numerical columns\n\n### ğŸ”¸ Visualize the data\n* ğŸ¥‡ **.hist()** to visualize each columns. \n* ğŸ¥‡ check for outliers.\n* ğŸ¥‡ check for scale and representations.\n* ğŸ¥‡ check for the tail heavy charts and note them for further actions.\n\n### ğŸ”¸ Create test set\n* ğŸ¥‡ using sklearn.modelSelection we can split the train and test data (80 - 20% usually but based on the size of the data)\n* ğŸ¥‡ Take care of stratified shuffle split if the represntation of some columns are not distributed properly, This call can be taken during thr previous Visualize data step\n\n### ğŸ”¸ Check for correlation \n* ğŸ¥‡ **.Corr()** method on df and check for corelation between numeric columns. ( The values range from -1 to 1. 0 means no correlation)\n\n### ğŸ”¸ Experiment Attribution Combinations\n* ğŸ¥‡ To get lesser columns and much meaningfull columns do feature combination.\n* ğŸ¥‡ Create derived columns such a way that the correlation to target is best fit.","metadata":{}},{"cell_type":"markdown","source":"# â›³ï¸ 3. Prepare the Data for ML Algo\n\n### ğŸ”¸ Preliminary Steps\n* ğŸ¥‡ Make sure you create a function for each operation, this will be helpful while creating the pipeline\n* ğŸ¥‡ Create a copy of train set (I usually keep same naming convention 'train_set') \n* ğŸ¥‡ Seperate out labels and target from train_set (train_set_label, train_set_target)\n\n### ğŸ”¸ Data Cleaning\n* ğŸ¥‡ Handle missing data\n* * ğŸ¥ˆ Missing Numerical data. \n* * * ğŸ¥‰ **.dropna()** to drop the missing data complete rows \n* * * ğŸ¥‰ **.drop()** to drop the missing complete columns\n* * * ğŸ¥‰ **.fillna()** to fill the data. (mean, median, std, constant are some of the option to pass)\n\n* * ğŸ¥‰ *Use Sklearn Simpleimputer to do the above, this is much better way to do* (mean, median, std, constant are some of the option to pass)\n* * ğŸ¥ˆ Missing categorical data. \n* * * ğŸ¥‰ Use Sklearn 1HotEncoder for converting categorical data into numerical data (This will work if the value counts are limited, otherwise we will endup with lot of columns). \n* * * ğŸ¥‰ Use ordinalEncoder to convert categorical data into uniq ID (numbers)\n\n\n### ğŸ”¸ Feature scaling\n* ğŸ¥‡ From above steps we have all the columns in place we need to scale all the columns (normalizing, standardaization)\n* ğŸ¥‡ You can make use of SKLearns.preprocessing MinMaxScaler or StdScaler for the same\n* ğŸ¥‡ If we have any tail heavy columns, while scaling we can make use of log method to scale\n* ğŸ¥‡ If we have multiple peaks we can go for RBF for scaling.\n\n\n### ğŸ”¸ Setup Transformation Pipelines\n* ğŸ¥‡ use SKLearn.pipeline to create pipelines for above steps\n* ğŸ¥‡ Create ColumnTransofrmers which runs all the above pipelines ","metadata":{}},{"cell_type":"markdown","source":"# â›³ï¸ 4. Select and Train Model\n\n### ğŸ”¸ Select Model\n* ğŸ¥‡ Try to use available models to gauge every models performance (LinearRegresor, Decision Tree, Random Forest)\n* ğŸ¥‡ Check each models performance with the our Performance measure we decided previously (train_set_label, train_set_target and predict the test_set without target and then compare prediction with target) \n\n### ğŸ”¸ Evaluate Model\n* ğŸ¥‡ If it performed poor in train_set itself then we are underfitting. We need to go for a powerfull model than the one we use\n* ğŸ¥‡ If it performed best in train_set (with RMSE ~0) and performed poor with test set then there are chances of overfitting. \n* ğŸ¥‡ For overfitting we can evaluate the model and try Crossvalidations\n* ğŸ¥‡ Always its better to have 2-5 models shortlisted at the end of this step. which can be finetuned further.","metadata":{}},{"cell_type":"markdown","source":"# â›³ï¸ 5. Fine-Tune the Model\n* ğŸ¥‡ We can use grid search CV, Randomized Search CV\n* ğŸ¥‡ We can use Ensembling to take all models and check the errors\n* ğŸ¥‡ Find best estimators (hyperparam tuning)","metadata":{}},{"cell_type":"markdown","source":"# â›³ï¸ 6. Evaluate the Model with Test set","metadata":{}},{"cell_type":"markdown","source":"# â›³ï¸ 7. Launch the model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}